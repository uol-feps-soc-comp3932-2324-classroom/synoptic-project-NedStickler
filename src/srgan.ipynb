{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from load_data import load_data\n",
    "import tensorflow as tf\n",
    "from tensorflow.nn import depth_to_space\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_blocks = 5\n",
    "downsample_factor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_path = r\"C:\\Users\\nedst\\Desktop\\synoptic-project-NedStickler\\.venv\\Lib\\site-packages\\tensorflow_datasets\"\n",
    "dataset, _ = load_data(package_path)\n",
    "dataset = dataset[:32, :, :, :]\n",
    "lr_dataset = np.array([image[::downsample_factor, ::downsample_factor, :] for image in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class PixelShuffle(keras.Layer):\n",
    "    def call(self, x):\n",
    "        return depth_to_space(x, 2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "def d_residual_block(x, n_filters, n_strides):\n",
    "    x = layers.Conv2D(n_filters, kernel_size=3, strides=n_strides, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def d_downsample_pair(x, n_filters):\n",
    "    x = d_residual_block(x, n_filters, 1)\n",
    "    x = d_residual_block(x, n_filters, 2)\n",
    "    return x\n",
    "\n",
    "def g_residual_block(x_in):\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x_in, x])\n",
    "    return x\n",
    "\n",
    "def discriminator():\n",
    "    # HR/SR input\n",
    "    inputs = layers.Input((None, None, 3))\n",
    "    x = layers.Rescaling(scale=1/127.5, offset=-1)(inputs)\n",
    "    \n",
    "    # First convolution blocks\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Residual downsampling blocks\n",
    "    x = d_residual_block(x, 64, 2)\n",
    "    x = d_downsample_pair(x, 128)\n",
    "    x = d_downsample_pair(x, 256)\n",
    "    x = d_downsample_pair(x, 512)\n",
    "\n",
    "    # Flatten and classify\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "\n",
    "def generator(residual_blocks):\n",
    "    # LR input\n",
    "    inputs = layers.Input((None, None, 3))\n",
    "    x_in = layers.Rescaling(scale=1/255)(inputs)\n",
    "\n",
    "    # First convolution\n",
    "    x_in = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x_in)\n",
    "    x_in = x = layers.PReLU(shared_axes=[1, 2])(x_in)\n",
    "\n",
    "    # Residual block set\n",
    "    for _ in range(residual_blocks):\n",
    "        x = g_residual_block(x)\n",
    "    \n",
    "    # Residual block without activation functions\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x_in, x])\n",
    "\n",
    "    # Upscaling blocks\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = PixelShuffle()(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = PixelShuffle()(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    # Final convolve\n",
    "    x = layers.Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.Rescaling(scale=127.5, offset=127.5)(x)\n",
    "\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class SRGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, vgg):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.vgg = vgg\n",
    "\n",
    "    def compile(self, d_optimiser, g_optimiser, bce_loss, mse_loss):\n",
    "        super().compile()\n",
    "        self.d_optimiser = d_optimiser\n",
    "        self.g_optimiser = g_optimiser\n",
    "        self.bce_loss = bce_loss\n",
    "        self.mse_loss = mse_loss\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"generator\": self.generator,\n",
    "            \"discriminator\": self.discriminator,\n",
    "            \"vgg\": self.vgg\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        lr_images, hr_images = data\n",
    "        batch_size = lr_images.shape[0]\n",
    "\n",
    "        # Train the discriminator\n",
    "        generated_images = self.generator(lr_images)\n",
    "        combined_images = keras.ops.concatenate([generated_images, hr_images])\n",
    "        d_labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.bce_loss(d_labels, predictions)\n",
    "        gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimiser.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Train the generator\n",
    "        misleading_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(lr_images)\n",
    "            predictions = self.discriminator(generated_images)\n",
    "            \n",
    "            g_loss = 0.001 * self.bce_loss(misleading_labels, predictions)\n",
    "\n",
    "            sr_vgg = tf.keras.applications.vgg19.preprocess_input(generated_images)\n",
    "            sr_vgg = self.vgg(sr_vgg) / 12.75\n",
    "\n",
    "            hr_vgg = tf.keras.applications.vgg19.preprocess_input(hr_images)\n",
    "            hr_vgg = self.vgg(hr_vgg) / 12.75\n",
    "\n",
    "            perceptual_loss = self.mse_loss(hr_vgg, sr_vgg)\n",
    "            g_total_loss = g_loss + perceptual_loss\n",
    "        \n",
    "        gradients = tape.gradient(g_total_loss, self.generator.trainable_weights)\n",
    "        self.g_optimiser.apply_gradients(zip(gradients,self.generator.trainable_weights))\n",
    "\n",
    "        losses = {\n",
    "            \"d_loss\": d_loss,\n",
    "            \"g_total_loss\": g_total_loss,\n",
    "            \"g_loss\": g_loss,\n",
    "            \"pereceptual_loss\": perceptual_loss\n",
    "        }\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.applications.VGG19(input_shape=(None, None, 3), weights=\"imagenet\", include_top=False)\n",
    "vgg = keras.Model(vgg.input, vgg.layers[20].output)\n",
    "\n",
    "srgan = SRGAN(discriminator=discriminator(), generator=generator(residual_blocks), vgg=vgg)\n",
    "srgan.compile(d_optimiser=keras.optimizers.Adam(learning_rate=0.0003), g_optimiser=keras.optimizers.Adam(learning_rate=0.0003), bce_loss=keras.losses.BinaryCrossentropy(), mse_loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "# srgan.fit(lr_dataset, dataset, epochs=1, steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan.generator.save(r\"C:\\Users\\nedst\\Desktop\\synoptic-project-NedStickler\\trained_models\\srgan_s32e1b1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_generator = keras.models.load_model(r\"C:\\Users\\nedst\\Desktop\\synoptic-project-NedStickler\\generators\\srgan_s2048e75b32.keras\")\n",
    "sr_imgs = loaded_generator(lr_dataset)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "fig.set_size_inches(10, 10)\n",
    "axs[0, 0].set_title(\"LR\")\n",
    "axs[0, 1].set_title(\"HR\")\n",
    "axs[0, 2].set_title(\"SR\")\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i, 0].imshow(lr_dataset[i+5])\n",
    "    axs[i, 1].imshow(dataset[i+5])\n",
    "    axs[i, 2].imshow(sr_imgs[i+5].numpy().astype(np.uint8))\n",
    "\n",
    "fig.savefig(r\"C:\\Users\\nedst\\Desktop\\synoptic-project-NedStickler\\images\\srgan_s2048e75b32.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
