{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from load_data import load_data\n",
    "from tensorflow.nn import depth_to_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_path = r\"C:\\Users\\nedst\\Desktop\\synoptic-project-NedStickler\\.venv\\Lib\\site-packages\\tensorflow_datasets\"\n",
    "dataset, _ = load_data(package_path)\n",
    "dataset = dataset[:2048, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_blocks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_residual_block(x, n_filters, n_strides):\n",
    "    x = layers.Conv2D(n_filters, kernel_size=3, strides=n_strides, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def d_downsample_pair(x, n_filters):\n",
    "    x = d_residual_block(x, n_filters, 1)\n",
    "    x = d_residual_block(x, n_filters, 2)\n",
    "    return x\n",
    "\n",
    "def g_residual_block(x_in):\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()(x_in, x)\n",
    "    return x\n",
    "\n",
    "def discriminator():\n",
    "    # HR/SR input\n",
    "    inputs = layers.Input((None, None, 3))\n",
    "    x = layers.Rescaling(scale=1/127.5, offset=-1)(inputs)\n",
    "    \n",
    "    # First convolution blocks\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Residual downsampling blocks\n",
    "    x = d_residual_block(x, 64, 2)\n",
    "    x = d_downsample_pair(x, 128)\n",
    "    x = d_downsample_pair(x, 256)\n",
    "    x = d_downsample_pair(x, 512)\n",
    "\n",
    "    # Flatten and classify\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "def generator(residual_blocks):\n",
    "    # LR input\n",
    "    inputs = layers.Input((None, None, 3))\n",
    "    x_in = layers.Rescaling(scale=1/255)(inputs)\n",
    "\n",
    "    # First convolution\n",
    "    x_in = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x_in)\n",
    "    x_in = x = layers.PReLU(shared_axes=[1, 2])(x_in)\n",
    "\n",
    "    # Residual block set\n",
    "    for _ in range(residual_blocks):\n",
    "        x = g_residual_block(x)\n",
    "    \n",
    "    # Residual block without activation functions\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()[x_in, x]\n",
    "\n",
    "    # Upscaling blocks\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = depth_to_space(x, 2)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, kernel_size=3, padding=\"same\")(x)\n",
    "    x = depth_to_space(x, 2)\n",
    "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    # Final convolve\n",
    "    x = layers.Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.Rescaling(scale=127.5, offset=127.5)(x)\n",
    "\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, vgg):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.vgg = vgg\n",
    "    \n",
    "    def compile(self, d_optimiser, g_optimiser, bce_loss, mse_loss):\n",
    "        super().compile()\n",
    "        self.d_optimiser = d_optimiser\n",
    "        self.g_optimiser = g_optimiser\n",
    "        self.bce_loss = bce_loss\n",
    "        self.mse_loss = mse_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
