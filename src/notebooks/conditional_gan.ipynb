{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_path = r\"C:\\Users\\nedst\\Desktop\\synoptic-project-NedStickler\\.venv\\Lib\\site-packages\\tensorflow_datasets\"\n",
    "dataset, labels = load_data(package_path)\n",
    "processed_labels = keras.utils.to_categorical(labels)\n",
    "\n",
    "num_channels = 3\n",
    "num_classes = 45\n",
    "latent_dim = 128\n",
    "image_size = 256\n",
    "\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "generator_in_channels = latent_dim + num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((256, 256, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense(32 * 32 * generator_in_channels),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((32, 32, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(3, (8, 8), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, labels = data\n",
    "        real_images = real_images / 255\n",
    "        batch_size = real_images.shape[0]\n",
    "        \n",
    "        # Reshape labels to be concatenated with generated examples\n",
    "        added_dims_labels = labels[:, :, None, None]\n",
    "        repeated_labels = ops.repeat(added_dims_labels, repeats=image_size**2)\n",
    "        reshaped_labels = ops.reshape(repeated_labels, (-1, image_size, image_size, num_classes))\n",
    "\n",
    "        # Create latent vectors and concatenate class labels for discriminator training\n",
    "        latent_vectors = keras.random.normal(shape=(batch_size, self.latent_dim), seed=self.seed_generator)\n",
    "        latent_vectors_with_labels = ops.concatenate([latent_vectors, labels], axis=1)\n",
    "\n",
    "        # Generate images\n",
    "        generated_images = self.generator(latent_vectors_with_labels)\n",
    "        \n",
    "        # Assemble images with labels\n",
    "        generated_images_with_labels = ops.concatenate([generated_images, reshaped_labels], -1)\n",
    "        real_images_with_labels = ops.concatenate([real_images, reshaped_labels], -1)\n",
    "        combined_images = ops.concatenate([generated_images_with_labels, real_images_with_labels])\n",
    "\n",
    "        # Create labels to train discriminator\n",
    "        discriminator_labels = ops.concatenate([ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))])\n",
    "\n",
    "        # Train discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(discriminator_labels, predictions)\n",
    "        gradients = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Create latent vectors and concatenate class labels for generator training\n",
    "        latent_vectors = keras.random.normal(shape=(batch_size, self.latent_dim), seed=self.seed_generator)\n",
    "        latent_vectors_with_labels = ops.concatenate([latent_vectors, labels], axis=1)\n",
    "\n",
    "        misleading_labels = ops.zeros((batch_size, 1))\n",
    "\n",
    "        # Train generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(latent_vectors_with_labels)\n",
    "            generated_images_with_labels = ops.concatenate([generated_images, reshaped_labels], -1)\n",
    "            predictions = self.discriminator(generated_images_with_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        gradients = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        \n",
    "        return {\"g_loss\": self.gen_loss_tracker.result(), \"d_loss\": self.disc_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset[:2048, :, :, :], processed_labels[:2048, :], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros(45)\n",
    "label[43] = 1\n",
    "label = label.reshape((1, 45))\n",
    "latent_vector = keras.random.normal(shape=(1, latent_dim))\n",
    "latent_vector_with_label = ops.concatenate([latent_vector, label], axis=1)\n",
    "latent_vector_with_label\n",
    "\n",
    "generated_image = cond_gan.generator.predict(latent_vector_with_label)\n",
    "processed_image = (generated_image[0] * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(processed_image.reshape((256, 256, 3)))\n",
    "plt.show()\n",
    "processed_image = processed_image.reshape(256, 256, 3)\n",
    "processed_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
