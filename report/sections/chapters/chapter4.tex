\chapter{Discussion}\label{chapter4}
This chapter evaluates our findings from the project, assesses whether we have met our project goals, offers conclusions, and suggests some ideas for future work.

\section{Evaluation}
The following section evaluates each of the findings presented at the end of the previous chapter.

\subsection{Individual model performance}
Reviewing SSIM and PSNR for the bicubic interpolation benchmark and our trained solutions shows that SRResNet performed the best, followed by bicubic, with SRGAN-DenseNet201 leading the SRGAN models. Whilst we implemented SRResNet as a model in its own right, the main aim was to produce SRGAN-based models that outperformed both SRResNet and traditional SR reconstruction methods. The reason that we did not achieve these results is very likely due to the training parameters used. To make our training methodology compliant with the constraints imposed by the training hardware, we reduced the number of total update iterations by a factor of 10. This allowed SRResNet to receive sufficient training, but SRGAN may have struggled to reach a good point in this amount of time. As well as this, we also had to reduce the batch size, number of patches, and dataset size significantly. A batch size of 15 is too small to provide a solid gradient, the number of patches may have left more to be desired in terms of capturing different features, and the small dataset size might have attributed to the model not being able to learn through limited training examples. Overall, the training parameters used in this project were insufficient for state-of-the-art results. Regardless of this, we still managed to produce SR reconstructions that are perceivably similar to the HR ground truth image, even if they did not beat existing benchmarks.

\subsection{Remote sensing specialisation}
The overall goal of this project was to solve the super-resolution reconstruction problem in remote sensing. We successfully identified a weakness of SRGAN when being applied to remote sensing imagery. We rectified this by training our solution specifically with remote sensing imagery. Our final results show that our SRGAN models produce significantly better results when applied to remote sensing imagery versus non-remote sensing imagery. This was a success as it helped us achieve our specific project aim relating to remote sensing imagery, however, there is still room for improvement. We could have adapted other model components to produce even better results in a remote sensing context, for example, training the perceptual loss classifiers on remote sensing imagery.

\subsection{Improving loss}
In chapter 2 we outlined how we would improve the loss function of the SRGAN model to create better SR reconstructions. The vanilla SRGAN model utilises VGG19 feature maps as a key component of the perceptual loss. We identified that VGG19 is now considered an old model in the timeline of neural network-based image classifiers, and identified a variety of newer, more performant classifiers that we could replace VGG with. This observation allowed us to improve upon the original SRGAN model, providing several SRGAN-based models that beat SRGAN-VGG54 (as proposed by Ledig \etal), and effectively allowing us to meet our main project aim.

\subsection{Addressing our conjecture}
In section~\ref{subsec:improving_loss} we provided the following conjecture: `using the feature maps from more accurate image classification models in the perceptual loss component of SRGAN-based models will increase SR reconstruction performance'. By systematically training and testing each of our models we were able to suggest a relationship between classifier accuracy and effectiveness of the feature maps as a loss component. Whilst this is an interesting observation, more research needs to be conducted before determining whether this conjecture holds much truth. In the context of this project, offering this conjecture was incredibly useful for producing better SR reconstruction capabilities with SRGAN, but investigating the true relationship does not align with our project goals and is therefore out of scope.

\subsection{Visual quality and MOS}
Briefly reviewing the super-resolution reconstructions from each of our solutions reveals a picture that does not necessarily fall in line with our SSIM and PSNR results. SSIM is designed to represent a score of how well the reconstructed image matches the HR image from a human perspective. From our results we can see that SRResNet produces the highest score for our test set. PSNR represents how well we have reversed the image degradation process, and again gives SRResNet the highest score. Reviewing the reconstructions of the test set reveals that SRResNet appears overly blurred when compared to the HR image. SRGAN-DenseNet201 produces the best results out of the SRGAN models, but the reconstructions also appear relatively blurred. From a quick review, SRGAN-VGG54 appears to produce the most visually pleasing results, but has the worst SSIM and second worst PSNR.\@ These observations suggest that MOS may have been a good performance metric for reviewing the quality of SR reconstructions, as it is the only true method for gauging quality from a human perspective. As MOS is entirely subjective it would be advisable to use it in conjunction with other performance metrics, but leaving it out altogether loses valuable insight.

\subsection{Noise and artefacts}
We can see pixel noise in some solutions, where pixels are seemingly random, incorrect colours. We can also see lower-frequency noise in the form of grid like patterns in the output of VGG22 and EfficientNetV2L. As the architecture of the classifiers has nothing to do with the visual output, the most likely explanation is that some classifiers provided a poor gradient for the model to learn from, and SRGAN has been unable to learn properly. This phenomenon suggests that classifier architecture may affect perceptual loss performance, which could be tested as a part of additional research on our conjecture.

\subsection{Project goals}
At the beginning of this project we set out six project goals that, if achieved, would ensure the success of the project. Here we will assess whether we have met each of the goals, and whether the aim of the project was met.

\textit{Select an appropriate deep learning-based SR reconstruction method to implement.} The first step outlined in chapter 1 was to select a deep learning-based method to SR reconstruction problem to implement as the foundation of our final solution. We successfully identified reasoning for and against using SRGAN, as well as reasoning as to why we did not select a simpler or more advanced model. Overall, we fully justified our reasoning for selecting SRGAN after completing extensive background research into the SR reconstruction problem.

\textit{Investigate remote sensing datasets for training, validation, and testing of the deep-learning based SR reconstruction method.} We successfully investigated commonly used remote sensing datasets by reviewing published literature. We filtered out datasets unfit for our project based on our goals and completed the necessary data preparation steps. Additionally, we included non-remote sensing evaluation sets to provide a frame of reference for our project aim. 

\textit{Adapt a feature of the deep learning-based method to improve SR reconstruction capabilities.} We provided a new method for improving the perceptual loss component of the SRGAN models and offered a conjecture to explore to describe the thought process behind the improvements. We systematically trained and tested model variations to observe the effect that the loss improvements had.

\textit{Train the deep learning-based method using the selected remote sensing dataset.} We trained SRGAN using the appropriately sized subset to ensure that training was successful. We systematically tested the appropriate training parameters to ensure that we complied with hardware restrictions and completed the training within a reasonable timeframe.

\textit{Evaluate the SR reconstruction capabilities of the adapted method trained on the remote sensing dataset.} We reviewed evaluation metrics commonly used in SR reconstruction and justified our reasoning for our selection. We calculated the evaluation metrics across our test set, and two additional evaluation sets for each of our trained models. We provided the evaluation values for our benchmark method, bicubic interpolation.

\textit{Produce better SR reconstructions than at least bicubic interpolation.} Bicubic interpolation acts as a benchmark for our solutions as it does not fully reverse the image degradation process. If we can perform better than bicubic interpolation then our model is somewhat successful at producing SR reconstructions. SRResNet is successful for both SSIM and PSNR, but all the SRGAN variations fail to beat bicubic interpolation. As mentioned before this is likely due to insufficient time spent training. We may consider this goal partially successful, as we have trained SRResNet to successfully beat bicubic interpolation, but not an SRGAN model.

\section{Conclusion}
The aim of this project was to provide a solution to the SR problem in remote sensing. We laid out a set of goals specifically designed to help us meet our aim. We systematically reviewed literature relating to the problem to help us select a foundation for our solution, which we implemented, trained, tested, and evaluated using industry standard techniques. We proved that we improved upon the solution we used as a foundation by altering the loss component, which yielded our SRGAN-DenseNet201 solution that has the highest performance of the SRGAN models. We were also successful in beating the performance of our benchmark, bicubic interpolation, with the SRResNet model used as the initialiser for our SRGAN models. We have fully evaluated each of our findings, and explored how we have met our goals. Whilst successful on many fronts, there are still improvements needed in some areas. Throughout the project we encountered problems with training due to hardware limitations, so accessing better hardware with more memory would allow us to produce better results. Caused by the hardware was the disappointing performance of our SRGAN models. Even though we were able to improve the performance of SRGAN, we were still unable to truly beat our benchmark solution, bicubic interpolation. Finally, in our analysis of performance metrics we concluded that MOS was too subjective and time-consuming to consider for this project, however evaluating our findings showed that MOS provided valuable insight into the human perception. Regardless of these shortcomings, we still met all of our goals, and achieved the overall project aim: solve the SR reconstruction problem in remote sensing.

\section{Ideas for future work}
Reviewing our findings and what we have achieved in the project reveals four directions for future research. Firstly, large improvements could be made to our results by simply using better training hardware. Increasing the speed and memory capacity of the hardware would allow us to properly train each model in less time, with a larger batch size, number of patches, and dataset size. This would provide a stronger gradient to learn from, with more local image regions from a greater variety of scenes, resulting in a far stronger model. Secondly, each of the pretrained classifiers that we use for the perceptual loss component in SRGAN training were trained on the same ImageNet dataset. It therefore may be beneficial to pretrain the classifiers on remote sensing imagery instead. The thought is that the classifiers will better extract features from remote sensing imagery, and therefore be better at finding the perceptual differences between images, leading to a stronger loss component. Thirdly, we identified in our evaluation that we may have been wrong about the usefulness of MOS as a performance metric. MOS provides a valuable human perception-based insight, which SSIM and PSNR are not able to perfectly replicate. As a result, we suggest calculating the MOS alongside SSIM and PSNR to gain a broader picture of model performance. Finally, we offered a conjecture on the role of accuracy in the performance of image classifier feature maps as the perceptual loss component in SRGAN training. We performed some basic analysis to review our initial conjecture, however dictated that full analysis into the relationship did not fall in line with our project goals and was therefore not necessary. Doing additional systematic investigation may reveal interesting insights that could improve performance further.