\chapter{Discussion}
\label{chapter4}
This chapter provides evaluates our findings from the project, assess whether we have met our project goals, offers conclusions and suggests some ideas for future work.

\section{Evaluation}
The following section overs evaluation of each of the findings presented at the end of the previous chapter and offers a conclusion to the project.

\subsection{Individual model performance}
Reviewing SSIM and PSNR for the bicubic interpolation benchmark and our trained solutions shows that SRResNet performed the best, followed by bicubic, with SRGAN-DenseNet201 leading the SRGAN models. Whilst we implemented SRResNet as a model in its own right, the main aim was to produce SRGAN based models that outperformed both SRResNet and traditional SR reconstruction methods. The reason that we did not achieve these results is very likely due to the training parameters used. To make our training methodology compliant with the constraints imposed by the training hardware we reduced the number of total update iterations by a factor of 10. This may have had the adverse affect of allowing SRResNet to recieve sufficient training, but SRGAN may have struggled to reach a good point in this amount of time. As well as this, we also had to reduce the batch size, number of patches, and dataset size significantly to remain within memory constraints. A batch size of 15 is too small to provide a solid gradient, the number of patches may have left more to be desired in terms of capturing different features, and the small dataset size might have attributed to the model not being able to learn through limited training examples. Overall, the training parameters used in this project were insufficient for state-of-the-art results, however we were severely limited by our training hardware. Regardless of this, we still managed to produce SR reconstructions that are perceivably similar to the HR ground truth image, even if they did not beat existing benchmarks.

\subsection{Remote sensing specialisation}
The overall goal of this project was to solve the super-resolution reconstruction problem in remote sensing. We identified in section~\ref{sec:selecting_an_approach} that the generalised SRGAN model could be trained on a remote sensing specific dataset with the aim of producing better results when applied to remote sensing imagery versus general imagery. To measure this difference we also tested our solutions on the Set5 and Set14 evaluation sets, both of which contain no remote sensing imagery. Every solution we trained on the remote sensing dataset created significantly SR reconstructions when applied to unseen remote sensing imagery versus generalised imagery. Training our solutions on remote sensing imagery therefore allowed us to solve the super-resolution problem specifically in the domain of remote sensing.

\subsection{Improving loss}
In chapter 2 we outlined how we would attempt to improve the loss function of the SRGAN model to create better SR reconstructions. The vanilla SRGAN model utilises VGG19 feature maps as a key component of the perceptual loss metric. We identified that VGG19 is now considered an old model in the timeline of neural network-based image classifiers, and identified a variety of newer, more performant classifiers that we could replace VGG with. Our results showed that, on the whole, more accurate image classifiers produced a greater SR reconstruction capability. SSIM showed this to be true across the board, and PSNR showed that only MobileNetV2 and EfficientNetV2L performed worse than the VGG54 loss component. \textcolor{blue}{Evaluate!}

\subsection{Addressing our conjecture}
In section~\ref{subsec:improving_loss} we provided the following conjecture: `using the feature maps from more accurate image classification models in the perceptual loss component of SRGAN-based models-based on the accuracy of the classifer used for the perceptual loss component will increase SR reconstruction performance'. By systematically training and testing our each of our models we were able to suggest a relationship between classifier accuracy and effectiveness of the feature maps as a loss component. Whilst this is an interesting obersvation, more research needs to be conducted before determining whether this conjecture holds much truth. In the context of this project, offering this conjecture was incredibly useful for producing better SR reconstruction capabilities with SRGAN, but investigating the true relationship does not align with our project goals and is therefore out of scope.

\subsection{Visual quality and MOS}
Briefly reviewing the super-resolution reconstructions from each of our solutions reveals a picture that does not necessarilly fall in line with our SSIM and PSNR results. SSIM is designed to represent a score of how well the reconstructed image matches the HR image from a human perspective. From our results we can see that SRResNet produces the highest score for our test set. PSNR represents how well we have reversed the image degradation process, and again gives SRResNet the highest score. Reviewing the reconstructions of the test set reveals that SRResNet appears overly blurred when compared to the HR image. SRGAN-DenseNet201 produces the best results out of the SRGAN models, but the reconstructions also appear relatively blurred. From a quick review, SRGAN-VGG54 appears to produce the most visually pleasing results, but has the lowest SSIM and second lowest PSNR.\@ These obersvations suggest that MOS may have been a good performance metric for reviewing the quality of SR reconstructions as it is the only true method for gaging quality from a human perspective. As MOS is entirely subjective it would be advisable to use it in conjunction with other performance metrics, but leaving it out alltogether looses valuabe insight.

\subsection{Noise and artefacts}
Similarly to the previous section, manually reviewing the solution outputs reveals more detial. We can see in some solutions pixel noise, where pixels are seemingly random, incorrect colours. We can also see lower-frequency noise in the form of grid like patterns in the output of VGG22 and EfficientNetV2L. As the architecture of the classifiers has nothing to do with the visual output, the most likely explanation is that some classifiers provided a poor gradient for the model to learn from, and as a result SRGAN has been unable to properly learn how to reconstruct images.

\subsection{Project goals}
At the begining of this project we set out six project goals that, if achieved, would ensure the success of the project. Here we will assess whether we have met each of the goals, and whether the aim of the project was met.

\textit{Select an appropriate deep learning-based SR reconstruction method to implement.} The first step outlined in our methods section was to select a deepl learning-based method to SR reconstruction problem to implement as the foundation of our final solution. We successfully identified reasoning for and against using SRGAN, as well as reasoning as to why we did not select another either more simple or more advanced model. Overall, we fully justified our reasoning for selecting SRGAN after completing extensive background research into the SR reconstruction problem.

\textit{Investigate remote sensing datasets for training, validation, and testing of the deep-learning based SR reconstruction method.} We successfully investigated commonly used remote sensing datasets by reviewing published literature. We filtered out datasets unfit for our project based on our goals and completed the necessary data preparation steps. We also included non-remote sensing evlauation sets to provide a frame of refernce for our project aim. 

\textit{Adapt a feature of the deep learning-based method to improve SR reconstruction capabilities.} We provided a new method for improving the perceptual loss component of the SRGAN models and offered a conjecture to explore to describe the thought process behind the improvements. We systematically trained and tested model variations to observe the affect that the loss improvements had.

\textit{Train the deep learning-based method using the selected remote sensing dataset.} We trained SRGAN using the appropriately sized data subset to ensure that training was succesful. We systematically tested the appropriate training parameters to ensure that we complied with hardware restrictions and completed the training within a reasonable timeframe.

\textit{Evaluate the SR reconstruction capabilities of the adapted method trained on the remote sensing dataset.} We reviewed evaluation metrics commonly used in SR reconstruction and justified our reasoning for our selection. We calculated the evaluation metrics across our test set, and two additional evaluation sets for each of our trained model. We provided the evaluation values for our benchmark method, bicubic interpolation.

\textit{Produce better SR reconstructions than at least bicubic interpolation.} Bicubic interpolation acts as a bench mark for our solutions as it does not fully reverse the image degradation process. If we can perform better than bicubic then our model is somewhat successful at producing SR reconstructions. SRResNet is succesful for both SSIM and PSNR, but all the SRGAN variations fail to beat bicubic interpolation. As mentioned before this is likely due to insufficient time spent training. We may consider this goal partially successful, as we have trained SRResNet to successfully beat bicubic interpolation, but we selected SRGAN as the model and failed on this front.

\section{Conclusions}
This section offers conclusions to the project in the form of strengths, limitations, and ideas for the continuation of the work completed in this project.

\subsection{Strengths}
Met all our goals

Successfully implemented everything that we set out to

The solution is fairly complex

\subsection{Limitations}
No access to sufficient training equpment

Didnt completely produce better results than bicubic

Not using MOS was an oversight

\subsection{Ideas for future work}
The most easily identifiable idea for future work is simply to perform training using better hardware with more memory. As a consequence of this, we would be able to increase batch size for a stronger gradient, increase the number of patches taken from each training instance for more data augmentation, increase the overall dataset size so that there were more training instances, and increase the number of update iterations so that the model has more time to learn. Based off of the results recieved by Ledig \etal in the SRGAN paper, our SRGAN models should have produced significantly better results than both bicubic interpolation and SRResNet. Training the models for longer with an increase in training parameter values is likely to achieve the same results that Ledig \etal initally received.  

Each of the pretrained classifiers that we use for the perceptual loss component in SRGAN training were trained on the same ImageNet dataset. ImageNet is not composed of remote sensing imagery, meaning the classifiers were extracted more general features than we required. It may therefore be beneficial to pretrain the classifiers to specifically classify remote sensing imagery. The thought is that the classifiers will better extract features from remote sensing imagery and therefore perform better as the perceptual loss component. This was not completed as a part of this project due to the extensive training received by the pretrained classifiers; it was very unlikely that we would be able to outperform even the generalised classifiers with the amount of training we could perform on our own remote sensing imagery classifier. Pretrained remote sensing imagery classifiers were difficult to locate for the purposes of this project.

We identified in our evaluation that we may have been wrong about the usefulness of MOS as a performance metric. MOS provides a valuable human perception-based insight, which SSIM and PSNR are not able to perfectly replicate. As a result, we suggest calculting the MOS alongside SSIM and PSNR to gain a broader picture of model performance.

Finally, we offered a conjecture on the role of accuracy in the performance of image classifier feature maps as the perceptual loss component in SRGAN training. We performed some basic analysis to review our initial conjeture, however dictated that full analysis into the relationship did not fall in line with our project goals and was therefore not necessary. As a result doing further systematic investigation into the relationship between accuracy and perceptual loss performance would be useful to further increase the performance of perceptual loss.

<Results and discussion requirements. Is it clear that\dots
\begin{itemize}
    \item Appropriate tests and evaluation were conducted and analysed to validate the quality of deliverables withihn the remit of the project?
    \item There are objective criteria for evaluating the achievement of the projects against the inital problem?
    \item These criteria are justified?
    \item The criteria have been used professionally to judge whether the problem has been solved?
\end{itemize}
>