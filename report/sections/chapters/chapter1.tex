\chapter{Introduction and Background Research}

% You can cite chapters by using '\ref{chapter1}', where the label must
% match that given in the 'label' command, as on the next line.
\label{chapter1}

% Sections and sub-sections can be declared using \section and \subsection.
% There is also a \subsubsection, but consider carefully if you really need
% so many layers of section structure.
\section{Introduction}

Super-resolution reconstruction describes the task of estimating a high-resolution representation of a low-resolution image~\cite{superResOverview}. It is a fundamental problem in the field of computer vision due to the ill-posed nature of the task: there are many `correct' HR representations of a single LR image~\cite{superResChallenges,superResRemoteSensingOverview}. SR image reconstruction is utilised in many domains, including remote sensing, medical imaging, surveillance, astronomy, and more~\cite{superResRemoteSensingChallenges, superResRemoteSensingOverview, superResMedicalImaging, superResSurveillance, superResAstronomy, superResUses}.

Remote sensing is the process of gathering data on an object without making physical contact~\cite{remoteSensing}. A predominant feature of remote sensing is aerial or satellite imagery, where images of the Earth are taken from aircraft of satellites respectively~\cite{ref}. Such images have proved useful in a variety of areas, including but not limited to urban planning~\cite{remoteSensingUses}, environmental analysis, land use management, and weather prediction~\cite{remoteSensingGANsReview}. \textcolor{blue}{References needed beyond this point.}

Remote sensing provides a particularly interesting set of conditions for the super resolution problem due to the constraints introduced by imaging hardware. Atmospheric conditions, hardware resolution and [something else here] can result in undesirable image quality, making SR reconstruction techniques attractive alternatives for producing high-resolution imagery.

SR reconstruction in remote sensing has matured as a field over recent years, with a host of proposed solutions to the problem. Traditional methods can be categorised as interpolation-based or reconstruction-based, with new learning-based methods proving particularly effective in the last decade. More recently the conception of generative deep learning architectures, such as generative adversarial networks, has led to a revived interest in the problem.

This project explores the effectiveness of GAN-based solutions to the super-resolution problem in remote sensing. A modification to a previous solution is suggested with the aim of improving model performance.

The problem: Super resolution in remote sensing. There exists a variety of solutions. Literature review on those solutions. Take SRGAN and improve it by improving the perceptual loss metric.

% Must provide evidence of a literature review. Use sections
% and subsections as they make sense for your project.
\clearpage
\section{Background research}\label{sec:background_research}
The following section details our investigation into the super-resolution reconstruction problem in remote sensing.
\subsection{The problem}
High-resolution (HR) images provide more detail than low-resolution (LR) images. The superior detail offered by HR imagery sanctions the existence of otherwise challenging exercises, including but not limited to weather prediction, urban mapping, and land cover observation~\cite{urbanMapping, mapping, cloudCover, vegetationMapping}. The most direct way of obtaining HR imagery is to increase the spatial resolution of the imaging hardware, however the amount of light available decreases and noise is introduced into the image~\cite{superResOverview}. An alternative method is to increase chip size to increase capacitance, but this results in undesireable inefficiencies and quickly becomes ineffective~\cite{superResOverview}. Increasing image resolution through hardware improvements is paired with high costs, and rapid changing application requirements do not complement the inflexible nature of such hardware~\cite{ref}. As a result, obtaining HR imagery becomes difficult when only improving imaging hardware.

The natural next step is to look to computational techniques to increase image resolution, leading us to the domain of super-resolution. The super-resolution problem describes the task of generating an HR representation from an LR image~\cite{ref}. We can formalise the problem as the inverse of the image degradation process, i.e.\ the process that turns some HR image into an LR image~\cite{imageDeg}. The image degradation process is as follows:
\begin{equation}\label{eq:image_deg}
    I_{LR} = D(B(I_{HR})) + \mathcal{N}
\end{equation}
This consists of three steps one-way functions: blurring ($B$), downsampling ($D$), and finally noise addition ($\mathcal{N}$). As each stage of the process is a one-way function the SR problem is ill-posed, i.e.\ multiple SR reconstructions could be perceived as `correct' for a single LR image~\cite{ref}.

Remote sensing describes the process of measuring the properties of objects without making physical contact, typically executed with aircraft or satellites~\cite{remoteSensing,remoteSensingImageProcessing}. As a species we rely on remote sensing for a variety of important practices, spanning numerous domains. This includes environmental assessment, global climate change detection, agriculture monitoring, renewable and non-renewable resource observation, meteorology and general weather analysis, land mapping, and military applications~\cite{remoteSensingImageProcessing, remoteSensingUses, remoteSensingGANsReview}.

Many spatial analyses require HR remote sensing imagery to be possible~\cite{ref}. We measure resolution of remote sensing imagery with spatial resolution, which is the physical area occupied by a single image pixel~\cite{ref}. In commerically available remote sensing datasets this ranges from 10cm to 1000m per pixel, with different applications for different resolutions~\cite{remoteSensingImageProcessing}. In many instances the resolution of imagery available for remote sensing application is too low, so it becomes very useful to construct HR imagery from LR inputs. Interestingly, we are able to describe equation~\ref{eq:image_deg} in real terms using remote sensing as our context. The blurring function, $B$, is introduced by the optical system capturing the spread of light, the downsampling function, $D$, describes the downsampling process enforced by the resolution of the sensing hardware, and $\mathcal{N}$ describes the addition of noise, usually Gaussian, imposed by atmospheric conditions or sensor failures~\cite{superResRemoteSensingOverview,superResRemoteSensingChallenges, remoteSensingDeepLearningReview, remoteSensingGANsReview}.

It is easy to see that SR has great potential in the field of remote sensing. This natural pairing, along with the importance of many of the practices conducted using remote sensing imagery, results in an interesting problem to solve with positive consequnces if successful. Therefore, investigating and developing solutions to the SR problem in remote sensing is the main goal of this project.

\subsection{Taxonomy of super-resolution solutions}
Before embarking on the investigation into various SR methods we must consider the taxonomy of the solution space. There are many different classifications we could consider based on various criteria. For example, we may choose to organise solutions based on the domain they operate in, resulting in a classification of either frequency domain or spatial domain~\cite{superResRemoteSensingOverview}. Alternatively, we could choose to split based on the knowledge of parameters we posess beforehand, leading to a classification of blind or non-blind~\cite{superResRemoteSensingOverview}. The complex nature of solutions, along with the increase of hybridised proposals, leads Fernandez-Beltran \etal\ to propose a simplified taxonomy of SR solutions. This taxonomy groups solutions based on their functional properties, and yields three main categories: reconstruction-based, learning-based, and hybrid-based ~\cite{superResRemoteSensingOverview}. For this project we will consider each of these classes as described by Fernandez-Beltran \etal\ We also consider interpolation-based methods, primarily used for upsampling purposes, and some additional methods used specifically to produce HR remote sensing imagery.

\subsection{Interpolation-based solutions}
Interpolation-based solutions serve one primary purpose: to upsample an image~\cite{interpolation}. Firstly, the image is scaled upwards, resulting in an increase of pixels. The relative position of pixels is maintained, and as a result we introduce unknown pixel values. Upscaling by a factor of four represents a pixel increase of $2^4 = 16$, or 15 unknown pixels for each known pixel. The next step of interpolation is to estimate the values of the unkown pixels, executed using various methods.

\subsubsection{}
Nearest neighbour interpolation uses the nearest neighbour algorithm to calculate the value of the missing pixels introduced by upsampling~\cite{nnInterpolation}. To find the value of an unknown pixel, we calculate the distance to the surrounding known pixels, i.e.\ the pixels known from the input image, and then take the closest known pixel value to our unknown pixel. Using nearest neighbour interpolation means no new pixel values are introduced; we always take a pixel from the input image. This results in an upsampled image with sharp edges.

Bilinear interpolation takes this idea a step further and assumes a linear relationship between pixels~\cite{bilnearInterpolation}. We use this assumption to calculate the missing pixels, where the missing values between two pixels are filled by following the line mapped between the two known pixel values. For example, take two known pixels, $x_0$ and $x_4$ with values 100 and 200 respectively, in an image upsampled by a factor of four, i.e.\ three unknown values between $x_0$ and $x_4$, called $x_1, x_2, x_3$. Bilinear interpolation would result in $x_1, x_2, x_3$ having values 125, 150 and 175 respectively, that is, the values between the known pixels follow a linear relationship. We can extend this to two dimensions, where we can calculate the value of any pixel in an image.

Bicubic interpolation assumes a cubic relationship between two pixels~\cite{bicubicInterpolation}. It makes the explicit assumption that the unknown values between two pixels sit on a curve instead of a line. To calculate this curve, to then calculate the missing pixel values, we must look to the pixel values either side of our known pixels. We use these to first calculate the `gradient' of our known pixels which we can then use to calculate the curve between the two pixels, called a spline. This allows us to place the unknown pixel values on this line. This results in a much smoother transition between known pixels, but fails to capture edge features.

There are numerous adaptations of interpolation based methods, each with different applications and effectiveness, including but not limited to edge directed interpolation, soft decision interpolation and fusion methods~\cite{interpolation}. Interpolation methods are computationally effective and do not require much memory, however the fundamental flaw is they only provide a solution for the downsampling step of the image degradation process, and not anti-blur and denoising properties~\cite{interpolation}. As a result interpolation methods often fall-flat when applied to natural imagery that has undergone the entire image degradation process.

\subsection{Reconstruction-based solutions}
Reconstruction-based methods improve upon the interpolation methods by considering the blur and noise effects of image degradation, providing a more complete solution and therefore better results. The common theme within this category of solutions is a three step approach to the problem: interpolation, feature extraction, and reconstruction~\cite{superResRemoteSensingOverview}. Firstly, images are upsampled using a standard interpolation technique, then features are extracted, and finally the image is reconstructed by aggregating the upsampled image and the extracted features. This provides a general framework for reconstruction-based methods, but the exact process for each stage is dependent on the specific method~\cite{superResRemoteSensingOverview}. Some notable examples include iterative back projection, point spread function deconvolution and gradient profiles.~\cite{superResRemoteSensingOverview}. Reconsutrction-based methods are important to mention in this project as the first wave of true SR techniques, however we will not cover them in detail due to the superiority of newer, learning-based methods.

\subsection{Learning-based solutions}
Learning-based methods aim to learn a generalised relationship between LR and HR images instead of attempting to reconstruct some LR image directly. This relationship is learned using training data, or numerous paired examples of LR and HR images. Once this relationship is learned we are able to apply it to new imagery to generate an SR output. Some examples include\dots

\subsection{Hybrid solutions}

\subsection{Additional solutions}

\subsection{Project goals}

<Section requirements. Have I\dots
\begin{itemize}
    \item Explained the problem clearly?
    \item Identified relevant areas for investigation and discussed them in the report under appropriate headings and critically?
    \item Reviewed previous attempts to solve this and similar problems?
    \item Justified any claims made using credible primary or secondary sources?
\end{itemize}
>